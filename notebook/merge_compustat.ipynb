{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "\n",
    "compustat_location = '../archive/compustat_feb.csv'\n",
    "breach_location = '../data/data_breaches_final.csv'\n",
    "bea_location = '../archive/BEA_database.csv'\n",
    "trends_tic_location = '../data/trends_tic.csv'\n",
    "trends_conm_location = '../data/trends_conm.csv'\n",
    "employees_location = '../data/employees.csv'\n",
    "out_location = '../data/COMPUSTAT_merged_cleaned_trends_feb.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = ['CORP', 'INC', 'LTD', 'CORPORATION', 'INCORPORATED', 'LLC', 'LTD', 'GROUP', 'NV', 'GRP', 'PLC']\n",
    "\n",
    "def clean_conm(name):\n",
    "    name = str(name)\n",
    "    name = re.sub(r'[^\\s\\w]+', '', name)\n",
    "    namewords = name.split()\n",
    "    resultwords = [word for word in namewords if word not in remove]\n",
    "    result = ' '.join(resultwords)\n",
    "    result = result.strip(' ')\n",
    "    return result\n",
    "\n",
    "def clean_tic(name):\n",
    "    name = str(name)\n",
    "    name = re.sub(r'[^\\s\\w]+', '', name)\n",
    "    result = name.strip(' ')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "compustat = pd.read_csv(compustat_location)\n",
    "compustat['datadate'] = pd.to_datetime(compustat['datadate'], format='%Y%m%d')\n",
    "# Remove any data from outside of US companies\n",
    "compustat = compustat[compustat['curcdq'] == 'USD']\n",
    "compustat['datamonth'] = compustat['datadate'].apply(lambda x: x.replace(day = 1))\n",
    "compustat['clean_name'] = compustat['conm'].apply(clean_conm)\n",
    "compustat['clean_tic'] = compustat['tic'].apply(clean_tic)\n",
    "compustat['fyear'] = compustat['datafqtr'].apply(lambda x: int(str(x)[0:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "breach = pd.read_csv(breach_location)\n",
    "breach['datacqtr'] = breach['yearquarter']\n",
    "breach['gvkey'] = breach['GVKEY']\n",
    "breach = breach[breach['match'] == 1]\n",
    "breach['Date Made Public'] = pd.to_datetime(breach['Date Made Public'], format='%B %d, %Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bea = pd.read_csv(bea_location)\n",
    "bea['datacqtr'] = bea['yearquarter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trends = pd.read_csv(trends_location).set_index('date')\n",
    "# trends_tic = trends.iloc[:, ::2]\n",
    "# trends_company = trends.iloc[:, 1::2]\n",
    "\n",
    "trends_company = pd.read_csv(trends_conm_location, index_col='date').stack()\n",
    "trends_company = trends_company.reset_index()\n",
    "trends_company['date'] = pd.to_datetime(trends_company['date'])\n",
    "trends_company.columns = ['datamonth', 'clean_name', 'trend_index_company']\n",
    "\n",
    "trends_tic = pd.read_csv(trends_tic_location, index_col='date').stack()\n",
    "trends_tic = trends_tic.reset_index()\n",
    "trends_tic['date'] = pd.to_datetime(trends_tic['date'])\n",
    "trends_tic.columns = ['datamonth', 'clean_tic', 'trend_index_tic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "employees = pd.read_csv(employees_location)\n",
    "employees['fyear'].fillna(employees['datadate'].apply(lambda x: int(str(x)[0:4]) + 1), inplace = True)\n",
    "employees = employees[['gvkey', 'fyear', 'emp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.merge(compustat, breach, how='outer', on=['gvkey', 'datacqtr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.merge(out, bea, how='left', on='datacqtr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.merge(out, trends_company, how='left', on=['datamonth','clean_name'])\n",
    "out = pd.merge(out, trends_tic, how='left', on=['datamonth','clean_tic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.merge(out, employees, how='left', on=['fyear', 'gvkey'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del out['Unnamed: 0']\n",
    "del out['orig_name']\n",
    "\n",
    "out['tic'] = out['tic_x']\n",
    "del out['tic_x']\n",
    "del out['tic_y']\n",
    "\n",
    "out['conm'] = out['conm_x']\n",
    "del out['conm_x']\n",
    "del out['conm_y']\n",
    "\n",
    "out['sic'] = out['sic_x']\n",
    "del out['sic_x']\n",
    "del out['sic_y']\n",
    "\n",
    "out['yearquarter'] = out['yearquarter_x']\n",
    "del out['yearquarter_x']\n",
    "del out['yearquarter_y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = out[~out['datadate'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436\n",
      "431\n"
     ]
    }
   ],
   "source": [
    "print(len(breach['gvkey'].unique()))\n",
    "print(len(out['gvkey'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantiles = out.groupby(by='gvkey').apply(lambda x: x['revtq'].iloc[0]).to_frame().quantile([0.25, 0.5, 0.75, 1])\n",
    "quantiles.index.names = ['quantile']\n",
    "quantiles.columns = ['revtq']\n",
    "\n",
    "out['rev_quart_1'] = 0\n",
    "out['rev_quart_2'] = 0\n",
    "out['rev_quart_3'] = 0\n",
    "out['rev_quart_4'] = 0\n",
    "out['first_rev'] = 0\n",
    "\n",
    "def classify_rev(comp):\n",
    "   \n",
    "    g = comp['gvkey'].iloc[0]\n",
    "    fr = comp['revtq'].iloc[0]\n",
    "    q1 = quantiles.loc[0.25].values[0]\n",
    "    q2 = quantiles.loc[0.5].values[0]\n",
    "    q3 = quantiles.loc[0.75].values[0]\n",
    "    q4 = quantiles.loc[1].values[0]\n",
    "    \n",
    "    out.loc[out['gvkey'] == g, 'first_rev'] = fr\n",
    "    \n",
    "    if fr <= q4 and fr > q3:\n",
    "        quartile = 4\n",
    "    elif fr <= q3 and fr > q2:\n",
    "        quartile = 3\n",
    "    elif fr <= q2 and fr > q1:\n",
    "        quartile = 2\n",
    "    else:\n",
    "        quartile = 1\n",
    "        \n",
    "    if quartile == 4:\n",
    "        out.loc[out['gvkey'] == g, 'rev_quart_4'] = 1\n",
    "        \n",
    "    if quartile == 3:\n",
    "        out.loc[out['gvkey'] == g, 'rev_quart_3'] = 1\n",
    "\n",
    "    if quartile == 2:\n",
    "        out.loc[out['gvkey'] == g, 'rev_quart_2'] = 1\n",
    "\n",
    "    if quartile == 1:\n",
    "        out.loc[out['gvkey'] == g, 'rev_quart_1'] = 1\n",
    " \n",
    "\n",
    "out.groupby(by='gvkey').apply(classify_rev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         305.600\n",
       "1         305.600\n",
       "2         305.600\n",
       "3         305.600\n",
       "4         305.600\n",
       "5         305.600\n",
       "6         305.600\n",
       "7         305.600\n",
       "8         305.600\n",
       "9         305.600\n",
       "10        305.600\n",
       "11        305.600\n",
       "12        305.600\n",
       "13        305.600\n",
       "14        305.600\n",
       "15        305.600\n",
       "16        305.600\n",
       "17        305.600\n",
       "18        305.600\n",
       "19        305.600\n",
       "20        305.600\n",
       "21        305.600\n",
       "22       5309.000\n",
       "23       5309.000\n",
       "24       5309.000\n",
       "25       5309.000\n",
       "26       5309.000\n",
       "27       5309.000\n",
       "28       5309.000\n",
       "29       5309.000\n",
       "           ...   \n",
       "22278      42.808\n",
       "22279      42.808\n",
       "22280      42.808\n",
       "22281      42.808\n",
       "22282      42.808\n",
       "22283      42.808\n",
       "22284      42.808\n",
       "22285       6.107\n",
       "22286       6.107\n",
       "22287       6.107\n",
       "22288       6.107\n",
       "22289       6.107\n",
       "22290       6.107\n",
       "22291       6.107\n",
       "22292       6.107\n",
       "22293       6.107\n",
       "22294       6.107\n",
       "22295       6.107\n",
       "22296       6.107\n",
       "22297       6.107\n",
       "22298       6.107\n",
       "22299       6.107\n",
       "22300       6.107\n",
       "22301       6.107\n",
       "22302       6.107\n",
       "22303       6.107\n",
       "22304       6.107\n",
       "22305       6.107\n",
       "22306       6.107\n",
       "22307       6.107\n",
       "Name: first_rev, Length: 22308, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['first_rev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7942\n",
      "4596\n",
      "4737\n",
      "5033\n"
     ]
    }
   ],
   "source": [
    "# out.loc[out['gvkey'] == 1013, 'rev_quart_1'] = 0\n",
    "#out.loc[out['gvkey'] == 1013, 'rev_quart_4']\n",
    "print(len(out[out['rev_quart_1'] == 1]))\n",
    "print(len(out[out['rev_quart_2'] == 1]))\n",
    "print(len(out[out['rev_quart_3'] == 1]))\n",
    "print(len(out[out['rev_quart_4'] == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_breach(company_record):\n",
    "    cols = list(set(breach.columns.to_list()) & set(company_record.columns.to_list()))\n",
    "    for i in range(150):\n",
    "        for col in cols:\n",
    "            company_record[col] = company_record[col].ffill(limit=1).bfill(limit=1) \n",
    "    return company_record\n",
    "\n",
    "out = out.set_index('datadate').groupby('gvkey').apply(closest_breach).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = out.drop(out[out['match'].isnull()].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_rev_companies = out[out['revtq'].isnull()]['gvkey'].unique()\n",
    "na_rev_comp = out[out['gvkey'].isin(na_rev_companies)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1013,   2005,   2019,   2269,   2968,   3082,   3238,   3643,\n",
       "         4640,   4674,   4678,   4685,   4699,   4739,   5568,   5643,\n",
       "         5786,   7647,   7982,   8007,   8245,   9783,  10035,  10187,\n",
       "        10726,  11856,  11861,  12976,  14275,  15199,  15509,  15545,\n",
       "        15617,  15782,  15855,  16116,  16245,  16384,  16784,  17934,\n",
       "        18498,  18683,  19873,  20067,  22306,  23107,  23821,  24481,\n",
       "        24905,  26156,  26272,  30188,  60923,  64336, 110250, 111537,\n",
       "       111662, 111819, 114524, 125054, 139662, 141913, 153769, 161989,\n",
       "       165993, 175607, 176928, 176939, 178012, 179027, 179534, 180405,\n",
       "       184167, 184180, 184498, 185419, 186342, 187462, 187969, 188856,\n",
       "       189860, 197559])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_rev_companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_csv(out_location, index=False, quoting=csv.QUOTE_ALL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
